{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and Tweet!\n",
    "=================\n",
    "\n",
    "This project has been inspired by - \n",
    "\n",
    "* Justin Blinder\n",
    "* http://projects.justinblinder.com/We-Read-We-Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "“We Read, We Tweet” geographically visualizes the dissemination of New York Times articles through Twitter. Each line connects the location of a tweet to the contextual location of the New York Times article it referenced. The lines are generated in a sequence based on the time in which a tweet occurs. The project explores digital news distribution in a temporal and spatial context through the social space of Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## all imports\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import bs4 #this is beautiful soup\n",
    "import time\n",
    "import operator\n",
    "import socket\n",
    "import cPickle\n",
    "import re # regular expressions\n",
    "\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scraping the wikipedia page for  'Web Scraping\" topic\n",
    "url = \"http://www.crummy.com/software/BeautifulSoup\"\n",
    "source = urllib2.urlopen(url).read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test some functions on the data before moving forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# check occurences of 'scraping' in the article\n",
    "print 'scraping' in source\n",
    "print source.count('scraping')\n",
    "position = source.find('Legal issues')\n",
    "print position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup\n",
    "Using this library for an efficient and easy web scraping in python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <title>\n",
      "   Beautiful Soup: We called him Tortoise because he taught us.\n",
      "  </title>\n",
      "  <link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "  <link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "  <meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "  <meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      " </head>\n",
      " <body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "  <img align=\"right\" src=\"10.1.jpg\" width=\"250\"/>\n",
      "  <br/>\n",
      "  <p>\n",
      "   You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.\n",
      "  </p>\n",
      "  <div align=\"center\">\n",
      "   <a href=\"bs4/download/\">\n",
      "    <h1>\n",
      "     Beautiful Soup\n",
      "    </h1>\n",
      "   </a>\n",
      "   <p>\n",
      "    \"A tremendous boon.\" -- Python411 Podcast\n",
      "   </p>\n",
      "   <p>\n",
      "    [\n",
      "    <a href=\"#Download\">\n",
      "     Download\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"bs4/doc/\">\n",
      "     Documentation\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"#HallOfFame\">\n",
      "     Hall of Fame\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"https://code.launchpad.net/beautifulsoup\">\n",
      "     Source\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "     Discussion group\n",
      "    </a>\n",
      "    ]\n",
      "   </p>\n",
      "   <small>\n",
      "    If Beautiful Soup has saved you a lot of time and money, the\n",
      "best way to pay me back is to check out\n",
      "    <a href=\"http://www.candlemarkandgleam.com/shop/constellation-games/\">\n",
      "     <i>\n",
      "      Constellation\n",
      "Games\n",
      "     </i>\n",
      "     , my sci-fi novel about alien video games\n",
      "    </a>\n",
      "    .\n",
      "    <br/>\n",
      "    You can\n",
      "    <a href=\"http://constellation.crummy.com/Constellation%20Games%20excerpt.html\">\n",
      "     read\n",
      "the first two chapters for free\n",
      "    </a>\n",
      "    , and the full novel starts at 5\n",
      "USD. Thanks!\n",
      "   </small>\n",
      "  </div>\n",
      "  <p>\n",
      "   <i>\n",
      "    If you have questions, send them to\n",
      "    <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "     the discussion\n",
      "group\n",
      "    </a>\n",
      "    . If you find a bug,\n",
      "    <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "     file it\n",
      "    </a>\n",
      "    .\n",
      "   </i>\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "  </p>\n",
      "  <ol>\n",
      "   <li>\n",
      "    Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "   </li>\n",
      "   <li>\n",
      "    Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "   </li>\n",
      "   <li>\n",
      "    Beautiful Soup sits on top of popular Python parsers like\n",
      "    <a href=\"http://lxml.de/\">\n",
      "     lxml\n",
      "    </a>\n",
      "    and\n",
      "    <a href=\"http://code.google.com/p/html5lib/\">\n",
      "     html5lib\n",
      "    </a>\n",
      "    , allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "   </li>\n",
      "  </ol>\n",
      "  <p>\n",
      "   Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class\n",
      "   <tt>\n",
      "    externalLink\n",
      "   </tt>\n",
      "   \", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "  </p>\n",
      "  <p>\n",
      "   Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   Interested?\n",
      "   <a href=\"bs4/doc/\">\n",
      "    Read more.\n",
      "   </a>\n",
      "   <a name=\"Download\">\n",
      "    <h2>\n",
      "     Download Beautiful Soup\n",
      "    </h2>\n",
      "   </a>\n",
      "  </p>\n",
      "  <p>\n",
      "   The current release is\n",
      "   <a href=\"bs4/download/\">\n",
      "    Beautiful Soup\n",
      "4.4.1\n",
      "   </a>\n",
      "   (September 28, 2015). You can install Beautiful Soup 4 with\n",
      "   <code>\n",
      "    pip install beautifulsoup4\n",
      "   </code>\n",
      "   . It's also available as the\n",
      "   <code>\n",
      "    python-beautifulsoup4\n",
      "   </code>\n",
      "   package in Debian, Ubuntu, and\n",
      "Fedora.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup 4 works on both Python 2 (2.6+) and Python 3.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the\n",
      "   <code>\n",
      "    bs4/\n",
      "   </code>\n",
      "   directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using\n",
      "   <code>\n",
      "    2to3\n",
      "   </code>\n",
      "   .)\n",
      "  </p>\n",
      "  <h3>\n",
      "   Beautiful Soup 3\n",
      "  </h3>\n",
      "  <p>\n",
      "   Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It is considered stable, and only\n",
      "critical security bugs will be fixed.\n",
      "   <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">\n",
      "    Here's\n",
      "the Beautiful Soup 3 documentation.\n",
      "   </a>\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup 3 works only under Python 2.x. It is licensed under\n",
      "the same license as Python itself.\n",
      "  </p>\n",
      "  <p>\n",
      "   The current release of Beautiful Soup 3 is\n",
      "   <a href=\"download/3.x/BeautifulSoup-3.2.1.tar.gz\">\n",
      "    3.2.1\n",
      "   </a>\n",
      "   (February 16,\n",
      "2012). You can install Beautiful Soup 3 with\n",
      "   <code>\n",
      "    pip install\n",
      "BeautifulSoup\n",
      "   </code>\n",
      "   . It's also available as\n",
      "   <code>\n",
      "    python-beautifulsoup\n",
      "   </code>\n",
      "   in Debian and Ubuntu, and as\n",
      "   <code>\n",
      "    python-BeautifulSoup\n",
      "   </code>\n",
      "   in Fedora.\n",
      "  </p>\n",
      "  <p>\n",
      "   You can also download the tarball and use\n",
      "   <code>\n",
      "    BeautifulSoup.py\n",
      "   </code>\n",
      "   in your project directly.\n",
      "   <a name=\"HallOfFame\">\n",
      "    <h2>\n",
      "     Hall of Fame\n",
      "    </h2>\n",
      "   </a>\n",
      "  </p>\n",
      "  <p>\n",
      "   Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "  </p>\n",
      "  <ul>\n",
      "   <li>\n",
      "    <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\n",
      "     \"Movable\n",
      " Type\"\n",
      "    </a>\n",
      "    , a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "   </li>\n",
      "   <li>\n",
      "    Reddit uses Beautiful Soup to\n",
      "    <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">\n",
      "     parse\n",
      "a page that's been linked to and find a representative image\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    Alexander Harrowell uses Beautiful Soup to\n",
      "    <a href=\"http://www.harrowell.org.uk/viktormap.html\">\n",
      "     track the business\n",
      " activities\n",
      "    </a>\n",
      "    of an arms merchant.\n",
      "   </li>\n",
      "   <li>\n",
      "    The developers of Python itself used Beautiful Soup to\n",
      "    <a href=\"http://svn.python.org/view/tracker/importer/\">\n",
      "     migrate the Python\n",
      "bug tracker from Sourceforge to Roundup\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    The\n",
      "    <a href=\"http://www2.ljworld.com/\">\n",
      "     Lawrence Journal-World\n",
      "    </a>\n",
      "    uses Beautiful Soup to\n",
      "    <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">\n",
      "     gather\n",
      "statewide election results\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    The\n",
      "    <a href=\"http://esrl.noaa.gov/gsd/fab/\">\n",
      "     NOAA's Forecast\n",
      "Applications Branch\n",
      "    </a>\n",
      "    uses Beautiful Soup in\n",
      "    <a href=\"http://laps.noaa.gov/topograbber/\">\n",
      "     TopoGrabber\n",
      "    </a>\n",
      "    , a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "   </li>\n",
      "  </ul>\n",
      "  <p>\n",
      "   If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or\n",
      "   <a href=\"http://groups.google.com/group/beautifulsoup/\">\n",
      "    the discussion\n",
      "group\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <h2>\n",
      "   Development\n",
      "  </h2>\n",
      "  <p>\n",
      "   Development happens at\n",
      "   <a href=\"https://launchpad.net/beautifulsoup\">\n",
      "    Launchpad\n",
      "   </a>\n",
      "   . You can\n",
      "   <a href=\"https://code.launchpad.net/beautifulsoup/\">\n",
      "    get the source\n",
      "code\n",
      "   </a>\n",
      "   or\n",
      "   <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "    file\n",
      "bugs\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <hr/>\n",
      "  <table>\n",
      "   <tr>\n",
      "    <td valign=\"top\">\n",
      "     <p>\n",
      "      This document (\n",
      "      <a href=\"/source/software/BeautifulSoup/index.bhtml\">\n",
      "       source\n",
      "      </a>\n",
      "      ) is part of Crummy, the webspace of\n",
      "      <a href=\"/self/\">\n",
      "       Leonard Richardson\n",
      "      </a>\n",
      "      (\n",
      "      <a href=\"/self/contact.html\">\n",
      "       contact information\n",
      "      </a>\n",
      "      ). It was last modified on Tuesday, September 29 2015, 00:25:43 Nowhere Standard Time and last built on Friday, January 22 2016, 00:00:01 Nowhere Standard Time.\n",
      "     </p>\n",
      "     <p>\n",
      "     </p>\n",
      "     <table class=\"licenseText\">\n",
      "      <tr>\n",
      "       <td>\n",
      "        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "         <img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/>\n",
      "        </a>\n",
      "       </td>\n",
      "       <td valign=\"top\">\n",
      "        Crummy is © 1996-2016 Leonard Richardson. Unless otherwise noted, all text licensed under a\n",
      "        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "         Creative Commons License\n",
      "        </a>\n",
      "        .\n",
      "       </td>\n",
      "      </tr>\n",
      "     </table>\n",
      "     <!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>-->\n",
      "    </td>\n",
      "    <td valign=\"top\">\n",
      "     <p>\n",
      "      <b>\n",
      "       Document tree:\n",
      "      </b>\n",
      "     </p>\n",
      "     <dl>\n",
      "      <dd>\n",
      "       <a href=\"http://www.crummy.com/\">\n",
      "        http://www.crummy.com/\n",
      "       </a>\n",
      "       <dl>\n",
      "        <dd>\n",
      "         <a href=\"http://www.crummy.com/software/\">\n",
      "          software/\n",
      "         </a>\n",
      "         <dl>\n",
      "          <dd>\n",
      "           <a href=\"http://www.crummy.com/software/BeautifulSoup/\">\n",
      "            BeautifulSoup/\n",
      "           </a>\n",
      "          </dd>\n",
      "         </dl>\n",
      "        </dd>\n",
      "       </dl>\n",
      "      </dd>\n",
      "     </dl>\n",
      "     Site Search:\n",
      "     <form action=\"/search/\" method=\"get\">\n",
      "      <input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "     </form>\n",
      "    </td>\n",
      "   </tr>\n",
      "  </table>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting bs4 object\n",
    "\n",
    "soup = bs4.BeautifulSoup(source)\n",
    "print soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://code.launchpad.net/beautifulsoup',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'http://www.candlemarkandgleam.com/shop/constellation-games/',\n",
       " 'http://constellation.crummy.com/Constellation%20Games%20excerpt.html',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://lxml.de/',\n",
       " 'http://code.google.com/p/html5lib/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n",
       " 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n",
       " 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n",
       " 'http://www.harrowell.org.uk/viktormap.html',\n",
       " 'http://svn.python.org/view/tracker/importer/',\n",
       " 'http://www2.ljworld.com/',\n",
       " 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n",
       " 'http://esrl.noaa.gov/gsd/fab/',\n",
       " 'http://laps.noaa.gov/topograbber/',\n",
       " 'http://groups.google.com/group/beautifulsoup/',\n",
       " 'https://launchpad.net/beautifulsoup',\n",
       " 'https://code.launchpad.net/beautifulsoup/',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://www.crummy.com/',\n",
       " 'http://www.crummy.com/software/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing some random bs4 functions \n",
    "\n",
    "first_tag = soup.find('a') # just one occurence\n",
    "#soup.findAll(\"a\") # all occurences\n",
    "first_tag.get('href')\n",
    "\n",
    "link_list = [l.get('href') for l in soup.findAll('a')]\n",
    "# link_list\n",
    "\n",
    "## just getting all the links that are external by searching for links starting with http\n",
    "\n",
    "# test = link_list[5]\n",
    "# test[0:4]\n",
    "\n",
    "external_links = []\n",
    "\n",
    "for l in link_list:\n",
    "    if l is not None and l[0:4] == 'http':\n",
    "        external_links.append(l)\n",
    "        \n",
    "external_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
       "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
       "<p>You didn't write that awful page. You're just trying to get some\n",
       "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
       "saving programmers hours or days of work on quick-turnaround\n",
       "screen scraping projects.</p>\n",
       "<div align=\"center\">\n",
       "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
       "<p>\"A tremendous boon.\" -- Python411 Podcast</p>\n",
       "<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a> ]</p>\n",
       "<small>If Beautiful Soup has saved you a lot of time and money, the\n",
       "best way to pay me back is to check out <a href=\"http://www.candlemarkandgleam.com/shop/constellation-games/\"><i>Constellation\n",
       "Games</i>, my sci-fi novel about alien video games</a>.<br/>You can\n",
       "<a href=\"http://constellation.crummy.com/Constellation%20Games%20excerpt.html\">read\n",
       "the first two chapters for free</a>, and the full novel starts at 5\n",
       "USD. Thanks!</small> </div>\n",
       "<p><i>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
       "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it</a>.</i></p>\n",
       "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
       "projects like screen-scraping. Three features make it powerful:\n",
       "\n",
       "</p><ol>\n",
       "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
       "for navigating, searching, and modifying a parse tree: a toolkit for\n",
       "dissecting a document and extracting what you need. It doesn't take\n",
       "much code to write an application\n",
       "\n",
       "</li><li>Beautiful Soup automatically converts incoming documents to\n",
       "Unicode and outgoing documents to UTF-8. You don't have to think\n",
       "about encodings, unless the document doesn't specify an encoding and\n",
       "Beautiful Soup can't detect one. Then you just have to specify the\n",
       "original encoding.\n",
       "\n",
       "</li><li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
       "to try out different parsing strategies or trade speed for\n",
       "flexibility.\n",
       "\n",
       "</li></ol>\n",
       "<p>Beautiful Soup parses anything you give it, and does the tree\n",
       "traversal stuff for you. You can tell it \"Find all the links\", or\n",
       "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
       "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
       "got bold text, then give me that text.\"\n",
       "\n",
       "</p><p>Valuable data that was once locked up in poorly-designed websites\n",
       "is now within your reach. Projects that would have taken hours take\n",
       "only minutes with Beautiful Soup.\n",
       "\n",
       "</p><p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
       "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
       "</p><p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
       "4.4.1</a> (September 28, 2015). You can install Beautiful Soup 4 with\n",
       "<code>pip install beautifulsoup4</code>. It's also available as the\n",
       "<code>python-beautifulsoup4</code> package in Debian, Ubuntu, and\n",
       "Fedora.\n",
       "\n",
       "</p><p>Beautiful Soup 4 works on both Python 2 (2.6+) and Python 3.\n",
       "\n",
       "</p><p>Beautiful Soup is licensed under the MIT license, so you can also\n",
       "download the tarball, drop the <code>bs4/</code> directory into almost\n",
       "any Python application (or into your library path) and start using it\n",
       "immediately. (If you want to do this under Python 3, you will need to\n",
       "manually convert the code using <code>2to3</code>.)\n",
       "\n",
       "</p><h3>Beautiful Soup 3</h3>\n",
       "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
       "from May 2006 to March 2012. It is considered stable, and only\n",
       "critical security bugs will be fixed. <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
       "the Beautiful Soup 3 documentation.</a>\n",
       "</p><p>Beautiful Soup 3 works only under Python 2.x. It is licensed under\n",
       "the same license as Python itself.\n",
       "\n",
       "</p><p>The current release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.1.tar.gz\">3.2.1</a> (February 16,\n",
       "2012). You can install Beautiful Soup 3 with <code>pip install\n",
       "BeautifulSoup</code>. It's also available as\n",
       "<code>python-beautifulsoup</code> in Debian and Ubuntu, and as\n",
       "<code>python-BeautifulSoup</code> in Fedora.\n",
       "\n",
       "</p><p>You can also download the tarball and use\n",
       "<code>BeautifulSoup.py</code> in your project directly.\n",
       "\n",
       "\n",
       "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
       "</p><p>Over the years, Beautiful Soup has been used in hundreds of\n",
       "different projects. There's no way I can list them all, but I want to\n",
       "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
       "these projects interesting, but it did make their completion easier:\n",
       "\n",
       "</p><ul>\n",
       "<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
       " Type\"</a>, a work of digital art on display in the lobby of the New\n",
       " York Times building, uses Beautiful Soup to scrape news feeds.\n",
       "\n",
       "</li><li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
       "a page that's been linked to and find a representative image</a>.\n",
       "\n",
       "</li><li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
       " activities</a> of an arms merchant.\n",
       "\n",
       "</li><li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
       "bug tracker from Sourceforge to Roundup</a>.\n",
       "\n",
       "</li><li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
       "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
       "statewide election results</a>.\n",
       "\n",
       "</li><li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
       "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
       "downloading \"high resolution USGS datasets.\"\n",
       "\n",
       "</li></ul>\n",
       "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
       "about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
       "group</a>.\n",
       "\n",
       "</p><h2>Development</h2>\n",
       "<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
       "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
       "bugs</a>.</p><hr/><table><tr><td valign=\"top\">\n",
       "<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Tuesday, September 29 2015, 00:25:43 Nowhere Standard Time and last built on Friday, January 22 2016, 00:00:01 Nowhere Standard Time.</p><p></p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2016 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></td><td valign=\"top\"><p><b>Document tree:</b>\n",
       "</p><dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dd></dl>\n",
       "</dd></dl>\n",
       "</dd></dl>\n",
       "\n",
       "\n",
       "Site Search:\n",
       "\n",
       "<form action=\"/search/\" method=\"get\">\n",
       "<input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
       "</form>\n",
       "</td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node = soup.html\n",
    "head = root_node.contents[0]\n",
    "body = root_node.contents[3]\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Abhishek/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"https://soic-indiana-csm.symplicity.com/students/index.php?_ksl=1&s=event&ss=cf&mode=form&id=481a8052e9d4a5ee06c4d6a42c2ccc2e&__paging=0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "sourc = \"https://soic-indiana-csm.symplicity.com/students/index.php?_ksl=1&s=event&ss=cf&mode=form&id=481a8052e9d4a5ee06c4d6a42c2ccc2e&__paging=0\"\n",
    "scrape = bs4.BeautifulSoup(sourc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
